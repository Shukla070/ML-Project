{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d31c304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5720ff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 'Two young, White males are outside near many bushes.', 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "multi30k_dataset = load_dataset(\"bentrevett/multi30k\")\n",
    "\n",
    "print(multi30k_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d9dd4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset loaded successfully!\n",
      "Dataset structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['en', 'de'],\n",
      "        num_rows: 29000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['en', 'de'],\n",
      "        num_rows: 1014\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['en', 'de'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n",
      "\n",
      "--- First Training Example ---\n",
      "English: Two young, White males are outside near many bushes.\n",
      "German:  Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"bentrevett/multi30k\")\n",
    "\n",
    "# The dataset is a 'DatasetDict' containing train, validation, and test splits.\n",
    "print(\"\\nDataset loaded successfully!\")\n",
    "print(\"Dataset structure:\")\n",
    "print(dataset)\n",
    "\n",
    "# Let's inspect the first example from the training set.\n",
    "# Each example is a dictionary with 'en' (English) and 'de' (German) keys.\n",
    "print(\"\\n--- First Training Example ---\")\n",
    "first_example = dataset['train'][0]\n",
    "print(f\"English: {first_example['en']}\")\n",
    "print(f\"German:  {first_example['de']}\")\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf87de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Tokenization ---\n",
      "Training tokenizer for language: 'en'...\n",
      "Training complete.\n",
      "Tokenizer saved to tokenizer_en.json\n",
      "Training tokenizer for language: 'de'...\n",
      "Training complete.\n",
      "Tokenizer saved to tokenizer_de.json\n",
      "\n",
      "--- Tokenization Demo ---\n",
      "\n",
      "Original English: A man in a blue shirt is running.\n",
      "Encoded IDs: [30, 93, 83, 57, 191, 160, 101, 353, 15]\n",
      "Tokens: ['A', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'running', '.']\n",
      "\n",
      "Original German: Ein Mann in einem blauen Hemd rennt.\n",
      "Encoded IDs: [109, 124, 100, 111, 276, 265, 561, 14]\n",
      "Tokens: ['Ein', 'Mann', 'in', 'einem', 'blauen', 'Hemd', 'rennt', '.']\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# step2_tokenize.py\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "def get_text_iterator(dataset, lang):\n",
    "    \"\"\"\n",
    "    Returns an iterator that yields sentences from the dataset for a given language.\n",
    "    \"\"\"\n",
    "    for example in dataset:\n",
    "        yield example[lang]\n",
    "\n",
    "def train_tokenizer(dataset, lang, vocab_size=10000):\n",
    "    \"\"\"\n",
    "    Trains a BPE tokenizer from a dataset iterator and saves it.\n",
    "    \"\"\"\n",
    "    # Initialize a tokenizer with a BPE model\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "    # Define the trainer with special tokens required for a seq2seq model\n",
    "    trainer = BpeTrainer(\n",
    "        vocab_size=vocab_size,\n",
    "        special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"]\n",
    "    )\n",
    "\n",
    "    # Get an iterator for the text data\n",
    "    text_iterator = get_text_iterator(dataset['train'], lang=lang)\n",
    "\n",
    "    # Train the tokenizer\n",
    "    print(f\"Training tokenizer for language: '{lang}'...\")\n",
    "    tokenizer.train_from_iterator(text_iterator, trainer=trainer)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # Save the tokenizer\n",
    "    output_path = f\"tokenizer_{lang}.json\"\n",
    "    tokenizer.save(output_path)\n",
    "    print(f\"Tokenizer saved to {output_path}\")\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "print(\"--- Starting Tokenization ---\")\n",
    "# Load the dataset from Step 1\n",
    "dataset = load_dataset(\"bentrevett/multi30k\")\n",
    "\n",
    "# Train and save the English tokenizer\n",
    "tokenizer_en = train_tokenizer(dataset, lang='en')\n",
    "\n",
    "# Train and save the German tokenizer\n",
    "tokenizer_de = train_tokenizer(dataset, lang='de')\n",
    "\n",
    "print(\"\\n--- Tokenization Demo ---\")\n",
    "# Example sentence\n",
    "english_sentence = \"A man in a blue shirt is running.\"\n",
    "german_sentence = \"Ein Mann in einem blauen Hemd rennt.\"\n",
    "\n",
    "# Encode the English sentence\n",
    "encoded_en = tokenizer_en.encode(english_sentence)\n",
    "print(f\"\\nOriginal English: {english_sentence}\")\n",
    "print(f\"Encoded IDs: {encoded_en.ids}\")\n",
    "print(f\"Tokens: {encoded_en.tokens}\")\n",
    "\n",
    "# Encode the German sentence\n",
    "encoded_de = tokenizer_de.encode(german_sentence)\n",
    "print(f\"\\nOriginal German: {german_sentence}\")\n",
    "print(f\"Encoded IDs: {encoded_de.ids}\")\n",
    "print(f\"Tokens: {encoded_de.tokens}\")\n",
    "print(\"-------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa649c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Test ---\n",
      "Model instantiated successfully.\n",
      "Shape of dummy source input: torch.Size([10, 4]) (SeqLen, BatchSize)\n",
      "Shape of dummy target input: torch.Size([12, 4]) (SeqLen, BatchSize)\n",
      "Shape of model output logits: torch.Size([12, 4, 10000]) (SeqLen, BatchSize, TgtVocabSize)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# This is a standard building block for Transformers.\n",
    "# It adds information about the position of each token in the sequence,\n",
    "# as the self-attention mechanism itself doesn't consider order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(-torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# Helper module that converts token IDs into embeddings.\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# The main model that brings everything together.\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        \n",
    "        # Using PyTorch's built-in Transformer components\n",
    "        self.transformer = nn.Transformer(d_model=emb_size,\n",
    "                                          nhead=nhead,\n",
    "                                          num_encoder_layers=num_encoder_layers,\n",
    "                                          num_decoder_layers=num_decoder_layers,\n",
    "                                          dim_feedforward=dim_feedforward,\n",
    "                                          dropout=dropout)\n",
    "        \n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src,\n",
    "                trg,\n",
    "                src_mask,\n",
    "                tgt_mask,\n",
    "                src_padding_mask,\n",
    "                tgt_padding_mask,\n",
    "                memory_key_padding_mask):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        \n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        \n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encoder(self.positional_encoding(self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        return self.transformer.decoder(self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask)\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz, device):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "# --- Main execution block to demonstrate the model ---\n",
    "\n",
    "# These parameters are chosen based on the project plan's advice to keep the model small. \n",
    "SRC_VOCAB_SIZE = 10000  # Placeholder from our tokenizer\n",
    "TGT_VOCAB_SIZE = 10000  # Placeholder from our tokenizer\n",
    "EMB_SIZE = 256          # d_model = 256 \n",
    "NHEAD = 8               # Number of attention heads\n",
    "FFN_HID_DIM = 512       # Feedforward network hidden dimension\n",
    "NUM_ENCODER_LAYERS = 3  # 3-4 layers recommended \n",
    "NUM_DECODER_LAYERS = 3  # 3-4 layers recommended \n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Instantiate the model\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                    NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
    "                                    FFN_HID_DIM)\n",
    "\n",
    "# Move model to the appropriate device\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "# Create some dummy input tensors to test the model's forward pass\n",
    "SRC_LEN = 10  # Length of the source sentence\n",
    "TGT_LEN = 12  # Length of the target sentence\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "src = torch.randint(0, SRC_VOCAB_SIZE, (SRC_LEN, BATCH_SIZE)).to(DEVICE)\n",
    "tgt = torch.randint(0, TGT_VOCAB_SIZE, (TGT_LEN, BATCH_SIZE)).to(DEVICE)\n",
    "\n",
    "# Create the necessary masks for the Transformer\n",
    "tgt_mask = generate_square_subsequent_mask(TGT_LEN, DEVICE)\n",
    "src_mask = torch.zeros((SRC_LEN, SRC_LEN), device=DEVICE).type(torch.bool)\n",
    "\n",
    "src_padding_mask = torch.zeros((BATCH_SIZE, SRC_LEN), device=DEVICE).type(torch.bool)\n",
    "tgt_padding_mask = torch.zeros((BATCH_SIZE, TGT_LEN), device=DEVICE).type(torch.bool)\n",
    "\n",
    "# Get the model's output\n",
    "logits = transformer(src, tgt, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "print(\"\\n--- Model Test ---\")\n",
    "print(f\"Model instantiated successfully.\")\n",
    "print(f\"Shape of dummy source input: {src.shape} (SeqLen, BatchSize)\")\n",
    "print(f\"Shape of dummy target input: {tgt.shape} (SeqLen, BatchSize)\")\n",
    "print(f\"Shape of model output logits: {logits.shape} (SeqLen, BatchSize, TgtVocabSize)\")\n",
    "print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29fce087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 907/907 [00:23<00:00, 38.83it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 113.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 5.386, Val loss: 4.471\n",
      "Saved new best model to 'best_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 907/907 [00:22<00:00, 39.73it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 107.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 4.074, Val loss: 3.836\n",
      "Saved new best model to 'best_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 907/907 [00:23<00:00, 38.17it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 103.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 3.567, Val loss: 3.441\n",
      "Saved new best model to 'best_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 907/907 [00:23<00:00, 38.32it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 93.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 3.216, Val loss: 3.167\n",
      "Saved new best model to 'best_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 907/907 [00:23<00:00, 39.24it/s]\n",
      "Validating: 100%|██████████| 32/32 [00:00<00:00, 101.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 2.950, Val loss: 2.944\n",
      "Saved new best model to 'best_model.pth'\n",
      "Training complete. Best model saved as 'best_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# step4_training_loop.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm import tqdm # For a nice progress bar\n",
    "import math\n",
    "\n",
    "# --- 1. Hyperparameters and Setup ---\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Define special symbols and their indices\n",
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "\n",
    "# Model Hyperparameters (must match step3_model.py)\n",
    "SRC_VOCAB_SIZE = 10000\n",
    "TGT_VOCAB_SIZE = 10000\n",
    "EMB_SIZE = 256\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "# Training Hyperparameters\n",
    "BATCH_SIZE = 32 # Reduced for easier training on consumer GPUs\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# --- 2. Data Loading and Preprocessing ---\n",
    "# Load tokenizers\n",
    "tokenizer_en = Tokenizer.from_file(\"tokenizer_en.json\")\n",
    "tokenizer_de = Tokenizer.from_file(\"tokenizer_de.json\")\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"bentrevett/multi30k\")\n",
    "\n",
    "# This function is crucial for preparing batches of data.\n",
    "# It tokenizes, adds special tokens, pads sequences to the same length,\n",
    "# and converts everything to tensors.\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for item in batch:\n",
    "        src_sentence, tgt_sentence = item['en'], item['de']\n",
    "        \n",
    "        # Tokenize and add Start-of-Sentence (SOS) and End-of-Sentence (EOS) tokens\n",
    "        src_tokens = [SOS_IDX] + tokenizer_en.encode(src_sentence).ids + [EOS_IDX]\n",
    "        tgt_tokens = [SOS_IDX] + tokenizer_de.encode(tgt_sentence).ids + [EOS_IDX]\n",
    "        \n",
    "        src_batch.append(torch.tensor(src_tokens))\n",
    "        tgt_batch.append(torch.tensor(tgt_tokens))\n",
    "\n",
    "    # Pad sequences to the length of the longest sequence in the batch\n",
    "    src_padded = nn.utils.rnn.pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_padded = nn.utils.rnn.pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    \n",
    "    return src_padded, tgt_padded\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(dataset['train'], batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(dataset['validation'], batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "# --- 3. Model, Loss, and Optimizer Initialization ---\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "# Initialize weights with a common strategy for Transformers\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "# Loss function: CrossEntropyLoss, ignoring padding tokens\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "# Optimizer: Adam is a standard choice for Transformers\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# --- 4. Training and Evaluation Functions ---\n",
    "def train_epoch(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    \n",
    "    for src, tgt in tqdm(dataloader, desc=\"Training\"):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        # Prepare target data for decoder input (shifted right) and loss calculation\n",
    "        tgt_input = tgt[:-1, :]\n",
    "        tgt_out = tgt[1:, :]\n",
    "\n",
    "        # Create masks\n",
    "        src_seq_len = src.shape[0]\n",
    "        tgt_seq_len = tgt_input.shape[0]\n",
    "        \n",
    "        tgt_mask = generate_square_subsequent_mask(tgt_seq_len, DEVICE)\n",
    "        src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "        \n",
    "        src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "        tgt_padding_mask = (tgt_input == PAD_IDX).transpose(0, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        # Zero gradients, calculate loss, backpropagate, and update weights\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(dataloader))\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(dataloader, desc=\"Validating\"):\n",
    "            src = src.to(DEVICE)\n",
    "            tgt = tgt.to(DEVICE)\n",
    "\n",
    "            tgt_input = tgt[:-1, :]\n",
    "            tgt_out = tgt[1:, :]\n",
    "\n",
    "            src_seq_len = src.shape[0]\n",
    "            tgt_seq_len = tgt_input.shape[0]\n",
    "\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_seq_len, DEVICE)\n",
    "            src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "            \n",
    "            src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "            tgt_padding_mask = (tgt_input == PAD_IDX).transpose(0, 1)\n",
    "\n",
    "            logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "            \n",
    "            loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "            losses += loss.item()\n",
    "\n",
    "    return losses / len(list(dataloader))\n",
    "\n",
    "\n",
    "# --- 5. Main Training Loop ---\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss = train_epoch(transformer, optimizer, train_dataloader)\n",
    "    val_loss = evaluate(transformer, val_dataloader)\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")\n",
    "    \n",
    "    # Save the model if it has the best validation loss so far\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(transformer.state_dict(), 'best_model.pth')\n",
    "        print(f\"Saved new best model to 'best_model.pth'\")\n",
    "\n",
    "print(\"Training complete. Best model saved as 'best_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9389f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
